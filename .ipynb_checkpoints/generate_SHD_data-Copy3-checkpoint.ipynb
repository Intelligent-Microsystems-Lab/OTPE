{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/t/tsumme/miniconda3/envs/otpe/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']='1'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import optax\n",
    "from OTPE import OSTL, OTTT, OTPE, Approx_OTPE, OTPE_mod2, Approx_OTPE_mod2, OTPE_flat, Approx_OTPE_flat\n",
    "\n",
    "from jax.tree_util import Partial, tree_map, tree_leaves, tree_structure, tree_unflatten\n",
    "import spiking_learning as sl\n",
    "\n",
    "import randman_dataset as rd\n",
    "import numpy as np\n",
    "from utils import gen_test_data, cos_sim_train_func, online_sim_train_func, test_func, custom_snn, bp_snn\n",
    "import torch\n",
    "import tonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "output_size = 20\n",
    "nlayers = 5\n",
    "dim = 3\n",
    "seq_len = 50\n",
    "slope = 10\n",
    "lr = \"001\"\n",
    "manifold_seed_val = 0\n",
    "init_seed_val = 3\n",
    "manifold_seed = jax.random.PRNGKey(manifold_seed_val)\n",
    "init_seed = jax.random.split(jax.random.PRNGKey(init_seed_val))[0]\n",
    "dtype = jnp.float32#jnp.bfloat16\n",
    "tau = dtype(2.)\n",
    "batch_sz = 128\n",
    "spike_fn = sl.fs(slope)\n",
    "n_iter = 5000\n",
    "layer_name = 256\n",
    "update_time = 'offline'\n",
    "if layer_name == 128:\n",
    "    layer_sz = lambda i: 128\n",
    "elif layer_name == 512:\n",
    "    layer_sz = lambda i: 512\n",
    "elif layer_name == 256:\n",
    "    layer_sz = lambda i: 256\n",
    "\n",
    "optimizer = optax.adamax(dtype(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = tonic.datasets.SHD.sensor_size\n",
    "train = tonic.datasets.SHD('data',train=True,transform=tonic.transforms.ToFrame(sensor_size=sensor_size,n_time_bins=seq_len))\n",
    "test = tonic.datasets.SHD('data',train=False,transform=tonic.transforms.ToFrame(sensor_size=sensor_size,n_time_bins=seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = jnp.load('train_data.npy')\n",
    "# train_labels = jnp.load('train_labels.npy')\n",
    "# test_data = jnp.load('test_data.npy')\n",
    "# test_labels = jnp.load('test_labels.npy')\n",
    "# val_data = jnp.load('val_data.npy')\n",
    "# val_labels = jnp.load('val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train)):\n\u001b[0;32m----> 4\u001b[0m     d,l \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     train_data\u001b[38;5;241m.\u001b[39mappend(d)\n\u001b[1;32m      6\u001b[0m     train_labels\u001b[38;5;241m.\u001b[39mappend(l)\n",
      "File \u001b[0;32m~/miniconda3/envs/otpe/lib/python3.11/site-packages/tonic/datasets/hsd.py:24\u001b[0m, in \u001b[0;36mHSD.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m file \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_on_system, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_filename), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# adding artificial polarity of 1 and convert to microseconds\u001b[39;00m\n\u001b[1;32m     23\u001b[0m events \u001b[38;5;241m=\u001b[39m make_structured_array(\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspikes/times\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e6\u001b[39m,\n\u001b[1;32m     25\u001b[0m     file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspikes/units\u001b[39m\u001b[38;5;124m\"\u001b[39m][index],\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     27\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m target \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][index]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/otpe/lib/python3.11/site-packages/h5py/_hl/dataset.py:841\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    839\u001b[0m mspace \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(selection\u001b[38;5;241m.\u001b[39mmshape)\n\u001b[1;32m    840\u001b[0m fspace \u001b[38;5;241m=\u001b[39m selection\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# Patch up the output for NumPy\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(len(train)):\n",
    "    d,l = train[i]\n",
    "    train_data.append(d)\n",
    "    train_labels.append(l)\n",
    "train_data = dtype(jnp.concatenate(train_data,axis=1))\n",
    "train_labels = dtype(jax.nn.one_hot(jnp.stack(train_labels),output_size))\n",
    "train_labels = jnp.tile(jnp.expand_dims(train_labels,axis=2),seq_len).transpose(2,0,1)\n",
    "\n",
    "val_data = train_data[:,0:len(train)//10]\n",
    "val_labels = train_labels[:,0:len(train)//10]\n",
    "\n",
    "\n",
    "train_data = train_data[:,len(train)//10:]\n",
    "train_labels = train_labels[:,len(train)//10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(seed2):\n",
    "    inds = jnp.arange(train_labels.shape[1])\n",
    "    inds = jax.random.permutation(seed2,inds,independent=True)\n",
    "    data = train_data[:,inds[0:batch_sz]]\n",
    "    labels = train_labels[:,inds[0:batch_sz]]\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_labels = []\n",
    "for i in range(len(test)):\n",
    "    d,l = test[i]\n",
    "    test_data.append(d)\n",
    "    test_labels.append(l)\n",
    "test_data = dtype(jnp.concatenate(test_data,axis=1))\n",
    "test_labels = dtype(jax.nn.one_hot(jnp.stack(test_labels),output_size))\n",
    "test_labels = jnp.tile(jnp.expand_dims(test_labels,axis=2),seq_len).transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jnp.save('train_data.npy',train_data)\n",
    "# jnp.save('train_labels.npy',train_labels)\n",
    "# jnp.save('test_data.npy',test_data)\n",
    "# jnp.save('test_labels.npy',test_labels)\n",
    "# jnp.save('val_data.npy',val_data)\n",
    "# jnp.save('val_labels.npy',val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry = [OTPE.initialize_carry(dtype=dtype)]*nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTTTmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OTTT, mod2=OTTT, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "OSTLmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OSTL, mod2=OSTL, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "OTPEmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OSTL, mod2=OTPE, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "Approx_OTPEmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OTTT, mod2=Approx_OTPE, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "carry = [OTPE.initialize_carry(dtype=dtype)]*nlayers\n",
    "params = OTPEmodel.init(init_seed,carry,train_data[0,:batch_sz])\n",
    "carry,s = OTPEmodel.apply(params,carry,train_data[0,:batch_sz])\n",
    "opt_state = optimizer.init(params)\n",
    "orig_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_carry = [OTPE.test_carry()]*nlayers\n",
    "val_carry,_ = OTPEmodel.apply(params,val_carry,val_data[0])\n",
    "\n",
    "test_carry = [OTPE.test_carry()]*nlayers\n",
    "test_carry,_ = OTPEmodel.apply(params,test_carry,test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_model = bp_snn(output_sz=output_size, n_layers=nlayers, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "bp_carry = carry\n",
    "bp_params = bp_model.init(init_seed,bp_carry,train_data[0,:batch_sz])\n",
    "struct = tree_structure(bp_params)\n",
    "bp_params = tree_unflatten(struct,tree_leaves(orig_params))\n",
    "\n",
    "bp_carry,s = bp_model.apply(bp_params,bp_carry,train_data[0,:batch_sz])\n",
    "bp_opt_state = optimizer.init(bp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry = tree_map(lambda x: jnp.zeros_like(x,dtype),carry)\n",
    "val_carry = tree_map(lambda x: jnp.zeros_like(x,dtype),val_carry)\n",
    "test_carry = tree_map(lambda x: jnp.zeros_like(x,dtype),test_carry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.split(init_seed)[0]\n",
    "cos = []\n",
    "cos_per = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "all_params = [params]*4\n",
    "all_params.append(bp_params)\n",
    "all_opt = [opt_state]*4\n",
    "all_opt.append(bp_opt_state)\n",
    "best_params = tree_map(jnp.zeros_like,all_params)\n",
    "best_val = [0]*4\n",
    "if update_time == 'offline':\n",
    "    best_val.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_training = jax.jit(Partial(cos_sim_train_func,OTTTmodel,\n",
    "                       Approx_OTPEmodel,\n",
    "                       OSTLmodel,\n",
    "                       OTPEmodel,\n",
    "                       bp_model,\n",
    "                       optimizer,\n",
    "                       carry,\n",
    "                       val_carry,\n",
    "                       val_data,\n",
    "                       val_labels,\n",
    "                       batch_sz,\n",
    "                       gen_data\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_training = jax.jit(Partial(online_sim_train_func,OTTTmodel,\n",
    "                       Approx_OTPEmodel,\n",
    "                       OSTLmodel,\n",
    "                       OTPEmodel,\n",
    "                       optimizer,\n",
    "                       carry,\n",
    "                       val_carry,\n",
    "                       val_data,\n",
    "                       val_labels,\n",
    "                       batch_sz,\n",
    "                       gen_data\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SHD_data/models/model_{}layer_{}_{}dim_{}seqlen_{}iter_{}seed_{}_sub_{}fs_adamax_lr{}'.format(nlayers,layer_name,dim,seq_len,0,init_seed_val,update_time,slope,lr),'wb') as file:\n",
    "#            pickle.dump(tree_map(jnp.float32,all_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_iter):        \n",
    "    \n",
    "    if update_time == 'offline':\n",
    "\n",
    "        all_loss, all_cosines, all_cosines_per, all_acc, all_params, all_opt, key = offline_training(all_params,all_opt,key)\n",
    "        \n",
    "\n",
    "        cos.append(np.stack(list(tree_map(jnp.float32,all_cosines))))\n",
    "        cos_per.append(np.stack(list((tree_map(jnp.float32,all_cosines_per)))))\n",
    "    \n",
    "    elif update_time == 'online':\n",
    "\n",
    "        all_loss, all_acc, all_params, all_opt, key = online_training(all_params,all_opt,key)\n",
    "\n",
    "\n",
    "    val_acc.append(np.stack(list(tree_map(jnp.float32,all_acc))))\n",
    "\n",
    "    train_loss.append(np.stack(list(tree_map(jnp.float32,all_loss))))\n",
    "    \n",
    "        #print(epoch)\n",
    "        #print(val_acc[-1])\n",
    "        #print(cos[-1])\n",
    "        #print(cos_per[-1])\n",
    "        #print(all_cosines_per)\n",
    "    \n",
    "    truth = np.greater(val_acc[-1],best_val).squeeze()\n",
    "    best_val = np.where(truth,val_acc[-1],best_val)\n",
    "    \n",
    "    for i in range(len(best_val)):\n",
    "        if truth[i]:\n",
    "            best_params[i] = all_params[i]\n",
    "    \n",
    "        # if (epoch+1)%200 == 0: #200\n",
    "        #     with open('SHD_data/models/model_{}layer_{}_{}dim_{}seqlen_{}iter_{}seed_{}_sub_{}fs_adamax_lr{}'.format(nlayers,layer_name,dim,seq_len,epoch+1,init_seed_val,update_time,slope,lr),'wb') as file:\n",
    "        #         pickle.dump(tree_map(jnp.float32,all_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SHD_data/models/model_{}layer_{}_{}dim_{}seqlen_best_{}seed_{}_sub_{}fs_adamax_lr{}'.format(nlayers,layer_name,dim,seq_len,init_seed_val,t_name,slope,lr),'wb') as file:\n",
    "#     pickle.dump(tree_map(jnp.float32,best_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTTT_acc = test_func(OTTTmodel,best_params[0],test_carry,(test_data,test_labels))\n",
    "Approx_OTPE_acc = test_func(Approx_OTPEmodel,best_params[1],test_carry,(test_data,test_labels))\n",
    "OSTL_acc = test_func(OSTLmodel,best_params[2],test_carry,(test_data,test_labels))\n",
    "OTPE_acc = test_func(OTPEmodel,best_params[3],test_carry,(test_data,test_labels))\n",
    "bp_acc = test_func(bp_model,best_params[4],test_carry,(test_data,test_labels))\n",
    "\n",
    "all_acc = (OTTT_acc,Approx_OTPE_acc,OSTL_acc,OTPE_acc,bp_acc)\n",
    "\n",
    "val_acc.append(np.stack(list(tree_map(jnp.float32,all_acc))))\n",
    "if update_time == 'online':\n",
    "    val_acc[-1] = val_acc[-1][0:4]\n",
    "print(val_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('SHD_data/layer_cosine_similarity/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_adamax_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),cos_per)\n",
    "np.save('SHD_data/model_cosine_similarity/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_adamax_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),cos)\n",
    "np.save('SHD_data/accuracy/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_adamax_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),val_acc)\n",
    "np.save('SHD_data/loss/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_adamax_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),train_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
