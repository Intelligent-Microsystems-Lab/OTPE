{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:Oryx not found! This library will still work but no summarywill be logged.\n",
      "/afs/crc.nd.edu/user/t/tsumme/miniconda3/envs/jax/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']='1'\n",
    "os.environ['CURL_CA_BUNDLE']='/etc/ssl/certs/ca-bundle.crt'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import optax\n",
    "from OTPE import OSTL, OTTT, OTPE, Approx_OTPE, OTPE_mod2, Approx_OTPE_mod2\n",
    "\n",
    "from jax.tree_util import Partial, tree_map, tree_leaves, tree_structure, tree_unflatten\n",
    "import spiking_learning as sl\n",
    "\n",
    "import randman_dataset as rd\n",
    "import numpy as np\n",
    "from utils import gen_test_data, cos_sim_train_func, online_sim_train_func, test_func, custom_snn, bp_snn\n",
    "import torch\n",
    "# import tonic\n",
    "from learned_optimization.research.general_lopt import prefab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 18:03:51.694605: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/Adam.learning_rate = 0.0003\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/build_gradient_estimators.gradient_estimator_fn = @FullESOrPMAP\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/build_gradient_estimators.sample_task_family_fn = @april28_distribution_bigger\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/FullES.loss_type = 'last_recompute'\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/FullES.recompute_samples = 100\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/FullES.sign_delta_loss_scalar = 1.0\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/FullES.truncation_schedule = @LogUniformLengthSchedule()\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/gradient_worker_compute.extra_metrics = False\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/GradientAccumulator.num_average = 20\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/GradientAccumulator.opt = @Adam()\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/GradientClipOptimizer.opt = @GradientAccumulator()\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/GradientLearner.init_theta_from_path =     'jul18_continue_on_bigger_2xbs_morestale_9264/params'\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/GradientLearner.meta_init = @HyperV2()\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/GradientLearner.reset_outer_iteration = True\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/GradientLearner.theta_opt = @GradientClipOptimizer()\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/HyperV2.lstm_hidden_size = 512\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/HyperV2.param_inits = 256\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/HyperV2.use_bugged_loss_features = False\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/LogUniformLengthSchedule.max_length = 200000\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/LogUniformLengthSchedule.min_length = 200\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/periodically_save_checkpoint.time_interval = 60\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/PMAPFullES.truncation_schedule = @LogUniformLengthSchedule()\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.lopt = @HyperV2()\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.num_estimators = 8\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.num_steps = 100000\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.outer_learner_fn = @GradientLearner\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.run_num_estimators_per_gradient = 1\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.staleness = 500\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.stochastic_resample_frequency = 200\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.summary_every_n = 25\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/run_train.trainer_batch_size = 512\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/VectorizedLOptTruncatedStep.num_tasks = 8\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/VectorizedLOptTruncatedStep.random_initial_iteration_offset = 0\n",
      "opt_from_checkpoint__d696a24c_c792_4062_958c_75b02534f914/VectorizedLOptTruncatedStep.trunc_sched = @NeverEndingTruncationSchedule()\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "output_size = 20\n",
    "nlayers = 5\n",
    "dim = 3\n",
    "seq_len = 50\n",
    "slope = 10\n",
    "lr = \"001\"\n",
    "manifold_seed_val = 0\n",
    "init_seed_val = 0\n",
    "manifold_seed = jax.random.PRNGKey(manifold_seed_val)\n",
    "init_seed = jax.random.split(jax.random.PRNGKey(init_seed_val))[0]\n",
    "dtype = jnp.float32#jnp.bfloat16\n",
    "tau = dtype(2.)\n",
    "batch_sz = 128\n",
    "spike_fn = sl.fs(slope)\n",
    "n_iter = 10000\n",
    "layer_name = 256\n",
    "update_time = 'offline'\n",
    "if layer_name == 128:\n",
    "    layer_sz = lambda i: 128\n",
    "elif layer_name == 512:\n",
    "    layer_sz = lambda i: 512\n",
    "elif layer_name == 256:\n",
    "    layer_sz = lambda i: 256\n",
    "\n",
    "optimizer = prefab.optax_lopt(n_iter)\n",
    "\n",
    "#optimizer = optax.adamax(dtype(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_size = tonic.datasets.SHD.sensor_size\n",
    "# train = tonic.datasets.SHD('data',train=True,transform=tonic.transforms.ToFrame(sensor_size=sensor_size,n_time_bins=seq_len))\n",
    "# test = tonic.datasets.SHD('data',train=False,transform=tonic.transforms.ToFrame(sensor_size=sensor_size,n_time_bins=seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = jnp.load('data/train_data.npy')\n",
    "train_labels = jnp.load('data/train_labels.npy')\n",
    "test_data = jnp.load('data/test_data.npy')\n",
    "test_labels = jnp.load('data/test_labels.npy')\n",
    "val_data = jnp.load('data/val_data.npy')\n",
    "val_labels = jnp.load('data/val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = []\n",
    "# train_labels = []\n",
    "# for i in range(len(train)):\n",
    "#     d,l = train[i]\n",
    "#     train_data.append(d)\n",
    "#     train_labels.append(l)\n",
    "# train_data = dtype(jnp.concatenate(train_data,axis=1))\n",
    "# train_labels = dtype(jax.nn.one_hot(jnp.stack(train_labels),output_size))\n",
    "# train_labels = jnp.tile(jnp.expand_dims(train_labels,axis=2),seq_len).transpose(2,0,1)\n",
    "\n",
    "# val_data = train_data[:,0:len(train)//10]\n",
    "# val_labels = train_labels[:,0:len(train)//10]\n",
    "\n",
    "\n",
    "# train_data = train_data[:,len(train)//10:]\n",
    "# train_labels = train_labels[:,len(train)//10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(seed2):\n",
    "    inds = jnp.arange(train_labels.shape[1])\n",
    "    inds = jax.random.permutation(seed2,inds,independent=True)\n",
    "    data = train_data[:,inds[0:batch_sz]]\n",
    "    labels = train_labels[:,inds[0:batch_sz]]\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = []\n",
    "# test_labels = []\n",
    "# for i in range(len(test)):\n",
    "#     d,l = test[i]\n",
    "#     test_data.append(d)\n",
    "#     test_labels.append(l)\n",
    "# test_data = dtype(jnp.concatenate(test_data,axis=1))\n",
    "# test_labels = dtype(jax.nn.one_hot(jnp.stack(test_labels),output_size))\n",
    "# test_labels = jnp.tile(jnp.expand_dims(test_labels,axis=2),seq_len).transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jnp.save('data/train_data.npy',train_data)\n",
    "# jnp.save('data/train_labels.npy',train_labels)\n",
    "# jnp.save('data/test_data.npy',test_data)\n",
    "# jnp.save('data/test_labels.npy',test_labels)\n",
    "# jnp.save('data/val_data.npy',val_data)\n",
    "# jnp.save('data/val_labels.npy',val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry = [OTPE.initialize_carry(dtype=dtype)]*nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTTTmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OTTT, mod2=OTTT, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "OSTLmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OSTL, mod2=OSTL, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "OTPEmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OSTL, mod2=OTPE, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "Approx_OTPEmodel = custom_snn(output_sz=output_size, n_layers=nlayers, mod1=OTTT, mod2=Approx_OTPE, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "carry = [OTPE.initialize_carry(dtype=dtype)]*nlayers\n",
    "params = OTPEmodel.init(init_seed,carry,train_data[0,:batch_sz])\n",
    "carry,s = OTPEmodel.apply(params,carry,train_data[0,:batch_sz])\n",
    "opt_state = optimizer.init(params)\n",
    "orig_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_carry = [OTPE.test_carry()]*nlayers\n",
    "val_carry,_ = OTPEmodel.apply(params,val_carry,val_data[0])\n",
    "\n",
    "test_carry = [OTPE.test_carry()]*nlayers\n",
    "test_carry,_ = OTPEmodel.apply(params,test_carry,test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_model = bp_snn(output_sz=output_size, n_layers=nlayers, spike_fn=spike_fn, layer_sz=layer_sz, dtype=dtype)\n",
    "bp_carry = carry\n",
    "bp_params = bp_model.init(init_seed,bp_carry,train_data[0,:batch_sz])\n",
    "struct = tree_structure(bp_params)\n",
    "bp_params = tree_unflatten(struct,tree_leaves(orig_params))\n",
    "\n",
    "bp_carry,s = bp_model.apply(bp_params,bp_carry,train_data[0,:batch_sz])\n",
    "bp_opt_state = optimizer.init(bp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry = tree_map(lambda x: jnp.zeros_like(x,dtype),carry)\n",
    "val_carry = tree_map(lambda x: jnp.zeros_like(x,dtype),val_carry)\n",
    "test_carry = tree_map(lambda x: jnp.zeros_like(x,dtype),test_carry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.split(init_seed)[0]\n",
    "cos = []\n",
    "cos_per = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "all_params = [params]*4\n",
    "all_params.append(bp_params)\n",
    "all_opt = [opt_state]*4\n",
    "all_opt.append(bp_opt_state)\n",
    "best_params = tree_map(jnp.zeros_like,all_params)\n",
    "best_val = [0]*4\n",
    "if update_time == 'offline':\n",
    "    best_val.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_training = jax.jit(Partial(cos_sim_train_func,OTTTmodel,\n",
    "                       Approx_OTPEmodel,\n",
    "                       OSTLmodel,\n",
    "                       OTPEmodel,\n",
    "                       bp_model,\n",
    "                       optimizer,\n",
    "                       carry,\n",
    "                       val_carry,\n",
    "                       val_data,\n",
    "                       val_labels,\n",
    "                       batch_sz,\n",
    "                       gen_data\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_training = jax.jit(Partial(online_sim_train_func,OTTTmodel,\n",
    "                       Approx_OTPEmodel,\n",
    "                       OSTLmodel,\n",
    "                       OTPEmodel,\n",
    "                       optimizer,\n",
    "                       carry,\n",
    "                       val_carry,\n",
    "                       val_data,\n",
    "                       val_labels,\n",
    "                       batch_sz,\n",
    "                       gen_data\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SHD_data/models/model_{}layer_{}_{}dim_{}seqlen_{}iter_{}seed_{}_sub_{}fs_adamax_lr{}'.format(nlayers,layer_name,dim,seq_len,0,init_seed_val,update_time,slope,lr),'wb') as file:\n",
    "#            pickle.dump(tree_map(jnp.float32,all_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_iter):        \n",
    "    \n",
    "    if update_time == 'offline':\n",
    "\n",
    "        all_loss, all_cosines, all_cosines_per, all_acc, all_params, all_opt, key = offline_training(all_params,all_opt,key)\n",
    "        \n",
    "\n",
    "        cos.append(np.stack(list(tree_map(jnp.float32,all_cosines))))\n",
    "        cos_per.append(np.stack(list((tree_map(jnp.float32,all_cosines_per)))))\n",
    "    \n",
    "    elif update_time == 'online':\n",
    "\n",
    "        all_loss, all_acc, all_params, all_opt, key = online_training(all_params,all_opt,key)\n",
    "\n",
    "\n",
    "    val_acc.append(np.stack(list(tree_map(jnp.float32,all_acc))))\n",
    "\n",
    "    train_loss.append(np.stack(list(tree_map(jnp.float32,all_loss))))\n",
    "    \n",
    "    #print(epoch)\n",
    "    #print(val_acc[-1])\n",
    "        #print(cos[-1])\n",
    "        #print(cos_per[-1])\n",
    "        #print(all_cosines_per)\n",
    "    \n",
    "    truth = np.greater(val_acc[-1],best_val).squeeze()\n",
    "    best_val = np.where(truth,val_acc[-1],best_val)\n",
    "    \n",
    "    for i in range(len(best_val)):\n",
    "        if truth[i]:\n",
    "            best_params[i] = all_params[i]\n",
    "    \n",
    "        # if (epoch+1)%200 == 0: #200\n",
    "        #     with open('SHD_data/models/model_{}layer_{}_{}dim_{}seqlen_{}iter_{}seed_{}_sub_{}fs_adamax_lr{}'.format(nlayers,layer_name,dim,seq_len,epoch+1,init_seed_val,update_time,slope,lr),'wb') as file:\n",
    "        #         pickle.dump(tree_map(jnp.float32,all_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SHD_data/models/model_{}layer_{}_{}dim_{}seqlen_best_{}seed_{}_sub_{}fs_adamax_lr{}'.format(nlayers,layer_name,dim,seq_len,init_seed_val,t_name,slope,lr),'wb') as file:\n",
    "#     pickle.dump(tree_map(jnp.float32,best_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66121906 0.6020318  0.58613074 0.6515018  0.7000883 ]\n"
     ]
    }
   ],
   "source": [
    "OTTT_acc = test_func(OTTTmodel,best_params[0],test_carry,(test_data,test_labels))\n",
    "Approx_OTPE_acc = test_func(Approx_OTPEmodel,best_params[1],test_carry,(test_data,test_labels))\n",
    "OSTL_acc = test_func(OSTLmodel,best_params[2],test_carry,(test_data,test_labels))\n",
    "OTPE_acc = test_func(OTPEmodel,best_params[3],test_carry,(test_data,test_labels))\n",
    "bp_acc = test_func(bp_model,best_params[4],test_carry,(test_data,test_labels))\n",
    "\n",
    "all_acc = (OTTT_acc,Approx_OTPE_acc,OSTL_acc,OTPE_acc,bp_acc)\n",
    "\n",
    "val_acc.append(np.stack(list(tree_map(jnp.float32,all_acc))))\n",
    "if update_time == 'online':\n",
    "    val_acc[-1] = val_acc[-1][0:4]\n",
    "print(val_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('SHD_data/layer_cosine_similarity/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_velo_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),cos_per)\n",
    "np.save('SHD_data/model_cosine_similarity/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_velo_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),cos)\n",
    "np.save('SHD_data/accuracy/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_velo_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),val_acc)\n",
    "np.save('SHD_data/loss/sim_{}layer_{}_{}dim_{}seqlen_{}iter_{}_sub_{}fs_velo_lr{}_{}seed'.format(nlayers,layer_name,dim,seq_len,n_iter,update_time,slope,lr,init_seed_val),train_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
